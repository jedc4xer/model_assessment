{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a894d0d-4ecd-4ff7-a73d-3629fe07c49e",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c1d394-ef01-4894-8460-ddc48625bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import graphviz # You need to install python-graphviz for this https://anaconda.org/conda-forge/python-graphviz\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# https://machinelearningmastery.com/data-preparation-gradient-boosting-xgboost-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a396726-059a-4050-961a-d53323b89622",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a68b58-ddc8-4752-a70e-61ac62751473",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_path = 'https://gen10datafund2202.blob.core.windows.net/jedscontainer/911_Calls_For_Service.csv'\n",
    "source_path = 'https://opendata.arcgis.com/api/v3/datasets/4f49eb825f564efa9a23cd103c4ba13b_0/downloads/data?format=csv&spatialRefId=4326'\n",
    "\n",
    "start = time.perf_counter()\n",
    "detroit_911 = pd.read_csv(blob_path, thousands = \",\")#, nrows = 100000)\n",
    "print(time.perf_counter() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5952704-c9a4-479a-bfb4-5f870ea7c21a",
   "metadata": {},
   "source": [
    "## Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fdb96f-e833-42db-988f-21ee42b03b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the dataframe so that I don't have to redownload it every time I want to refresh.\n",
    "detroit_df = detroit_911.copy()\n",
    "\n",
    "# Count all the null values in the columns\n",
    "null_values = detroit_df.isnull().sum().reset_index().rename(columns = {'index':'feature', 0: \"null_values\"})\n",
    "null_values.sort_values(by = 'null_values', ascending = False, inplace = True)\n",
    "null_values['null_ratio'] = (null_values['null_values'] / detroit_df.shape[0]) * 100\n",
    "null_values['total'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85754878-7031-4b72-b5d2-44ab44581e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "plt.title('Features with Null Values', fontsize = 22)\n",
    "\n",
    "null_ax = sns.barplot(data = null_values[(null_values['null_ratio'] > 0)], x='total', y='feature', color = 'lightgrey', edgecolor = 'black')\n",
    "null_ax1 = sns.barplot(data = null_values[(null_values['null_ratio'] > 0)], x='null_ratio', y='feature', palette = 'deep', edgecolor = 'black')\n",
    "\n",
    "null_ax.set_ylabel(\"\")\n",
    "null_ax.set_xlabel('% of Values that are Null', fontsize = 18)\n",
    "\n",
    "null_ax.tick_params(bottom = False, left = False)\n",
    "for c in null_ax.containers:\n",
    "    labels = []\n",
    "    for v in c:\n",
    "        if (h := v.get_width()) == 100:\n",
    "            lab = \"\"\n",
    "        elif (h := v.get_width()) > 14:\n",
    "            lab = f' {(h/100)*100:0.1f}% of total'\n",
    "        elif (h := v.get_width()) > 7:\n",
    "            lab = f'  {\" \"*25}- {(h/100)*100:0.2f}%'\n",
    "        elif (h := v.get_width()) > 3:\n",
    "            lab = f'  {\" \"*16}- {(h/100)*100:0.2f}%'\n",
    "        else:\n",
    "            lab = f'{\" \"*16}- {(h/100)*100:0.2f}%'\n",
    "        labels.append(lab)\n",
    "\n",
    "    null_ax.bar_label(c,labels=labels,label_type = 'center',fontsize = 18,color= 'black')#, weight = 'bold')\n",
    "    \n",
    "null_ax.set(xticklabels = [])\n",
    "sns.despine(bottom = True, left = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe9ea4-c835-4aff-b5ab-e55912fd5447",
   "metadata": {},
   "outputs": [],
   "source": [
    "detroit_df.head(5).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46f454b-cf42-4b79-b899-c8e4518a2965",
   "metadata": {},
   "source": [
    "### Drop Unused Features\n",
    "> We dropped features that... Explain this further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac550f9b-e904-4059-b2dd-5a5b85ce3d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that will not be used in algorithm\n",
    "detroit_df.drop(\n",
    "    columns = [\n",
    "        'incident_id',\n",
    "        'zip_code',\n",
    "        'oid',\n",
    "        'respondingunit',\n",
    "        'agency',\n",
    "        'X',\n",
    "        'Y',\n",
    "        'longitude',\n",
    "        'latitude',\n",
    "        'incident_address',\n",
    "        'block_id',\n",
    "        'category'\n",
    "    ], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409b62ea-d1cc-4591-b91a-15ebca859eac",
   "metadata": {},
   "source": [
    "### Fix Missing Priorities\n",
    "> Explain what we are doing here. (Remember that some of the priorities were missing so we matched the call description up with a matching call description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b696114a-55cd-46b1-b6da-5b0643b09328",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_priorities = detroit_df.groupby(by = ['priority'])['calldescription'].apply(lambda x: ', '.join(x)).reset_index()\n",
    "mapped_priorities['calldescription'] = mapped_priorities['calldescription'].apply(lambda x: \", \".join(_.strip() for _ in set(x.split(\",\"))))\n",
    "\n",
    "priority_dict = {}\n",
    "for priority in mapped_priorities['priority'].unique():\n",
    "    priority_dict[priority] = mapped_priorities[(mapped_priorities.priority == priority)]['calldescription'].values.tolist()[0]\n",
    "\n",
    "del priority_dict[\" \"]\n",
    "\n",
    "def get_priority(current_priority, call_descrip):\n",
    "    if current_priority != \" \":\n",
    "        return current_priority\n",
    "    for key in priority_dict.keys():\n",
    "        if call_descrip in priority_dict[key]:\n",
    "            return key   \n",
    "    return 'FAIL'\n",
    "\n",
    "detroit_df['new_priority'] = detroit_df.apply(lambda row: get_priority(row.priority, row.calldescription), axis = 1)\n",
    "\n",
    "detroit_df.drop(columns = ['priority'], inplace = True)\n",
    "detroit_df.rename(columns = {'new_priority': 'priority'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba29610-4fd8-4179-88f9-eb6288e47c39",
   "metadata": {},
   "source": [
    "### Drop two of the time columns\n",
    "> Explain why we did this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea85101-7688-40bc-90b1-aff3eafa1851",
   "metadata": {},
   "outputs": [],
   "source": [
    "detroit_df.drop(columns = ['totaltime','totalresponsetime'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157936a-452b-4dd8-9777-183220a23397",
   "metadata": {},
   "source": [
    "### Convert timestamp to weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4a1d57-2618-4358-aed8-3fa30d084366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_weekday(time_stamp):\n",
    "    time = dt.datetime.strptime(time_stamp, '%Y/%m/%d %H:%M:%S+00').date()\n",
    "    return dt.datetime.strftime(time, '%A')\n",
    "    \n",
    "detroit_df['weekday'] = detroit_df['call_timestamp'].apply(lambda x: return_weekday(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aa69ed-7d5b-4328-ad6c-67401f10ced5",
   "metadata": {},
   "source": [
    "### Convert Timestamp to Part of Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36860f10-12cc-46cd-b1e5-7f93f5baa041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daypart(time_stamp):\n",
    "    time = dt.datetime.strptime(time_stamp, '%Y/%m/%d %H:%M:%S+00')\n",
    "    time = dt.datetime.strftime(time, '%H:%M:%S')\n",
    "    if time < \"06:00\":\n",
    "        time_of_day = \"Early Morning\"\n",
    "    elif time >= \"06:00\" and time < \"10:00\":\n",
    "        time_of_day = \"Morning\"\n",
    "    elif time >= \"10:00\" and time < \"12:00\":\n",
    "        time_of_day = \"Late Morning\"\n",
    "    elif time >= \"12:00\" and time < \"15:00\":\n",
    "        time_of_day = \"Afternoon\"\n",
    "    elif time >= \"15:00\" and time < \"18:00\":\n",
    "        time_of_day = \"Late Afternoon\"\n",
    "    elif time >= \"18:00\" and time < \"21:00\":\n",
    "        time_of_day = \"Early Evening\"\n",
    "    elif time >= \"21:00\":\n",
    "        time_of_day = \"Evening\"\n",
    "    else:\n",
    "        time_of_day = \"FAILED\"\n",
    "    return time_of_day\n",
    "\n",
    "detroit_df['day_part'] = detroit_df['call_timestamp'].apply(lambda x: get_daypart(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2477f5d-8e9d-415c-8599-e459f1f75ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize = (20,5))\n",
    "axs[0].set_title(\"Distribution of Calls by Day Part\", fontsize = 20)\n",
    "axs[1].set_title(\"Distribution of Calls by Weekday\", fontsize = 20)\n",
    "sns.histplot(data = detroit_df, x = 'day_part', ax = axs[0])\n",
    "sns.histplot(data = detroit_df, x = 'weekday', ax = axs[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1612ec0b-a1f1-477b-95e5-0a99d444d8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "detroit_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fc221c-a314-47ec-b5a7-eec5fd6a7b73",
   "metadata": {},
   "source": [
    "### Drop columns that will not be used for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd1c3e2-0f1f-4c1e-b6c1-ac4864e85723",
   "metadata": {},
   "outputs": [],
   "source": [
    "detroit_df.drop(columns = ['callcode','call_timestamp','precinct_sca'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43170251-5b91-4d87-b2d8-2eeae6010a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initially wanted to use call description, but it reduced the accuracy of the prediction\n",
    "detroit_df.drop(columns = ['calldescription'], inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57ae9cb-40ce-4d4b-a985-b6adf9d893f6",
   "metadata": {},
   "source": [
    "### Create a save point so that data reloading is unneccessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b02ad-15fb-4520-9230-7fb38a17f28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_detroit = detroit_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64da8bda-1929-4c27-a62a-fe046d7aba43",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "### To avoid overwriting detroit_df during a reload, run from this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329239f7-6de3-4fce-8648-552d957db1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_detroit.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977847bd-2cd9-4567-83ad-01d693b0a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "detroit_df = backup_detroit.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3091a2-61b4-435f-997b-4129e0d75c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "detroit_df_subset = detroit_df.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c091d-0185-4ab2-83c8-bc34e7206b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (17,5))\n",
    "plt.title('Distribution of a subset of the data', fontsize = 20)\n",
    "sns.histplot(data = detroit_df_subset, x='time_on_scene')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6070bd-3207-4c64-89c2-dac8bb2cd1ea",
   "metadata": {},
   "source": [
    "### Establish what we are trying to predict.\n",
    "> We want to know, given certain characteristics, what is the likelihood that an officers<br>\n",
    "time on scene will be more than the average (around 32.7 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92db97d-4e4e-464a-b9d1-e11bedbcd4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = detroit_df['time_on_scene'].mean()\n",
    "detroit_df['on_scene_time_gt_mean'] = detroit_df['time_on_scene'].apply(lambda x: 1 if x > data_mean else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b4440-1a44-499e-9e7b-371c9eb3c797",
   "metadata": {},
   "source": [
    "### Drop the column that was used to generate our prediction column because it will correlate too highly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555a69b5-d3a6-49cc-b628-20261264b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "detroit_df.drop(columns = ['time_on_scene'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82616d95-30f0-443d-9435-c2663acc3a26",
   "metadata": {},
   "source": [
    "### Establish X - The independent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb75c03f-a356-499f-b74c-deef09bf4e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = detroit_df.drop(columns = ['on_scene_time_gt_mean']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa37c685-8069-468b-a96f-6826695bdf79",
   "metadata": {},
   "source": [
    "### Establish Y - The dependent feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcb4b32-f212-4a1e-af50-33e1abc0c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = detroit_df['on_scene_time_gt_mean'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058f8185-af17-40c1-b5aa-fbab58abfa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1380a4-6eae-4382-8034-2a3692d5ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = pd.get_dummies(X)\n",
    "# detroit_dummied.shape\n",
    "\n",
    "# It is better to use One-Hot-Encoding than get_dummies because OHE saves the exploded categories into its object, but we are using get_dummies for ease\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c20f31-7d1b-40d5-b3be-3b875d56d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded.columns = X_encoded.columns.str.replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e91edbc-ccc4-4c55-8082-6a776f6bc3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e109b97c-5024-4808-ad56-ad482ff0abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039d546e-7337-47d9-9d0a-5d7dfafe225b",
   "metadata": {},
   "source": [
    "### Preserve the time needed to run various combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5161a5-3bd8-4009-bf34-87af52a01409",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_time = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abe9e6e-6350-48ad-bf5f-df2f1017f8f0",
   "metadata": {},
   "source": [
    "## Primary Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3164a1-e900-48ec-8ed2-a6878854ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9dc24f-bde8-4a78-8b38-df14f2fa7737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X, y):\n",
    "    \"\"\" This model provides the baseline so we can test the accuracy of our model. \"\"\"\n",
    "    X_test, X_train, y_test, y_train = train_test_split(X_encoded, y_res, test_size=0.25, random_state = 1)\n",
    "\n",
    "    log_reg = LogisticRegression(max_iter = 10000)\n",
    "\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    log_coef = log_reg.coef_\n",
    "    log_intercept = log_reg.intercept_\n",
    "\n",
    "    score = log_reg.score(X_test, y_test)\n",
    "\n",
    "    predictions = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f2b80a-81a6-4e40-a212-389b95fd22aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_classifier(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size = 0.2, random_state = 42, stratify = y\n",
    "    )\n",
    "    \n",
    "    optimal_params = GridSearchCV(\n",
    "        estimator=xgb.XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            seed = 42,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.5\n",
    "        ),\n",
    "        param_grid=param_grid1,\n",
    "        scoring='roc_auc',\n",
    "        verbose=2,\n",
    "        n_jobs=10,\n",
    "        cv=3\n",
    "    )\n",
    "    \n",
    "    optimal_params.fit(X_train, \n",
    "                y_train, \n",
    "                verbose = False,\n",
    "                early_stopping_rounds=10, \n",
    "                eval_metric='auc',\n",
    "                eval_set=[(X_test, y_test)]\n",
    "               )\n",
    "    \n",
    "    print(optimal_params.best_params_)\n",
    "    return(optimal_params.best_params_)\n",
    "    #possible save hyper results\n",
    "    \n",
    "def run_classifier(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size = 0.2, random_state = 42, stratify = y\n",
    "    )\n",
    "    \n",
    "    xgb_reg = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                               seed = 42,\n",
    "                               subsample=0.9,\n",
    "                               colsample_bytree=0.5)\n",
    "    \n",
    "    xgb_reg.fit(X_train,\n",
    "                y_train,\n",
    "                verbose = 2,\n",
    "                early_stopping_rounds=10,\n",
    "                eval_metric='auc',\n",
    "                eval_set=[(X_test, y_test)]\n",
    "               )\n",
    "    print(f'Score: {xgb_reg.score}')\n",
    "    \n",
    "def get_first_tree(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size = 0.2, random_state = 42, stratify = y\n",
    "    )\n",
    "    \n",
    "    xgb_reg = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                               seed = 42,\n",
    "                               subsample=0.9,\n",
    "                               colsample_bytree=0.5,\n",
    "                               n_estimators=1)\n",
    "    \n",
    "    xgb_reg.fit(X_train, y_train)\n",
    "    return xgb_reg\n",
    "    \n",
    "hyper_scores = {\n",
    "    'max_depth': [],\n",
    "    'learning_rate': [],\n",
    "    'gamma': [], \n",
    "    'reg_lambda': [],\n",
    "    'scale_pos_weight': [],\n",
    "    'accuracy': []\n",
    "}\n",
    "\n",
    "param_grid1 = {\n",
    "    'max_depth': [3,4,5,6,7,8],\n",
    "    'learning_rate': [0.1, 0.01, 0.05],\n",
    "    'gamma': [0, 0.25, 1.0, 2.0], \n",
    "    'reg_lambda': [10.0, 20, 100],\n",
    "    'scale_pos_weight': [1,2,3,4,5],\n",
    "}\n",
    "\n",
    "param_grid2 = {\n",
    "    'max_depth': [4],\n",
    "    'learning_rate': [0.1, 0.5, 1],\n",
    "    'gamma': [0.25], \n",
    "    'reg_lambda': [10.0, 20, 100],\n",
    "    'scale_pos_weight': [3],\n",
    "}\n",
    "\n",
    "size = 3000\n",
    "\n",
    "X_subset = X_encoded.head(size)\n",
    "y_subset = y.head(size)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "#optimal_metrics = tune_classifier(X_subset,y_subset)\n",
    "#running_time.append([size, time.perf_counter() - start_time, optimal_metrics])\n",
    "\n",
    "#run_classifier(X_subset, y_subset)\n",
    "tree_model = get_first_tree(X_subset, y_subset)\n",
    "print(running_time)\n",
    "\n",
    "# Best at 100_000 {'gamma': 1.0, 'learning_rate': 0.1, 'max_depth': 5, 'reg_lambda': 10.0, 'scale_pos_weight': 3}\n",
    "\n",
    "# num_rows\truntime\truntime_mins\n",
    "# 0\t20000\t355.851673\t5.930861\n",
    "# 1\t50000\t1072.080725\t17.868012\n",
    "# 2\t100000\t2874.519241\t47.908654"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d89a25-9502-42cc-b557-b9c3c2e68429",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cdad3d-c1a9-484a-b71a-57146c1c7b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tuning():\n",
    "    elapsed_df = pd.read_csv('data_output/tuning_results.csv')\n",
    "    \n",
    "    plt.rcParams['xtick.labelsize'] = 13\n",
    "    plt.rcParams['ytick.labelsize'] = 13\n",
    "\n",
    "    fig = plt.subplots(figsize = (15,5))\n",
    "    plt.title(\"Time for Tuning\", fontsize = 22)\n",
    "    ax = sns.scatterplot(data = elapsed_df, x = 'num_rows', y='runtime_mins', s = 180, alpha = 0.8, edgecolor = 'black', color = 'red')\n",
    "    ax = sns.lineplot(data = elapsed_df[(elapsed_df.num_rows != 3000)], x = 'num_rows', y='runtime_mins', linestyle = 'dashed', color= 'red')\n",
    "    plt.axvspan(110000, 150000, color = 'red', alpha = .2)\n",
    "\n",
    "    ax.set_xlabel('Number of Rows', fontsize = 14)\n",
    "    ax.set_ylabel('Runtime (Minutes)', fontsize = 14)\n",
    "    ax.ticklabel_format(style = 'plain')\n",
    "    ax.tick_params(size = 12)\n",
    "    ax.set_ylim([-10,100])\n",
    "    ax.set_xlim([-10,130000])\n",
    "    ax.xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "    ax.annotate(' Total\\n\\nSystem\\n\\nFailure', xy=(116500,20), fontsize = 18)\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('graphs/tuning_time.png', transparent = False)\n",
    "#visualize_tuning()\n",
    "\n",
    "def visualize_optimization_results():\n",
    "    elapsed_df = pd.read_csv('data_output/tuning_results.csv')\n",
    "    fig, axs = plt.subplots(5,1, figsize = (17,10), gridspec_kw={'height_ratios':[.3,.3,.3,.3,.3]}, sharex = False)\n",
    "    fig.suptitle(\"Optimal Parameters (average of results)\", fontsize = 22)\n",
    "    sns.scatterplot(data = elapsed_df, x = 'num_rows', y='gamma', s = 180, alpha = 0.8, edgecolor = 'black', color = 'red', ax=axs[0])\n",
    "    sns.scatterplot(data = elapsed_df, x = 'num_rows', y='learning_rate', s = 180, alpha = 0.8, edgecolor = 'black', color = 'red', ax=axs[1])\n",
    "    sns.scatterplot(data = elapsed_df, x = 'num_rows', y='max_depth', s = 180, alpha = 0.8, edgecolor = 'black', color = 'red', ax=axs[2])\n",
    "    sns.scatterplot(data = elapsed_df, x = 'num_rows', y='reg_lambda', s = 180, alpha = 0.8, edgecolor = 'black', color = 'red', ax=axs[3])\n",
    "    sns.scatterplot(data = elapsed_df, x = 'num_rows', y='scale_pos_weight', s = 180, alpha = 0.8, edgecolor = 'black', color = 'red', ax=axs[4])\n",
    "    \n",
    "    targets = ['gamma','learning_rate','max_depth','reg_lambda','scale_pos_weight']\n",
    "    gap = [.1,.006,.15,5,-.43]\n",
    "    for i, ax in enumerate(axs):\n",
    "        ax.set_title(targets[i].replace(\"_\",\" \").title(), fontsize = 19)\n",
    "        ax.axhline(elapsed_df[targets[i]].mean(), color = 'black', linestyle = 'dashed')\n",
    "        avg = elapsed_df[targets[i]].mean()\n",
    "        ax.annotate(f'Average Best: {round(avg,3)}', xy=(20000, avg + (gap[i])), fontsize = 15)\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('')\n",
    "        ax.tick_params(size = 12)\n",
    "        ax.xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('graphs/optimal_params.png')\n",
    "    \n",
    "visualize_optimization_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027357d7-8dfe-483f-a006-80b398980213",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_first_attempts():\n",
    "    score_frame = pd.read_csv('data_output/prediction_scores_xgb_baseline.csv')\n",
    "    sns.set_style('ticks')\n",
    "\n",
    "    plt.rcParams['xtick.labelsize'] = 13\n",
    "    plt.rcParams['ytick.labelsize'] = 13\n",
    "\n",
    "    fig, axs = plt.subplots(3, 1, figsize = (18,13), gridspec_kw={'height_ratios':[.5,.5,.3]}, sharex = False)\n",
    "\n",
    "    axs[0].set_title('Model Predicting Time On Scene (less than 32 minutes on scene)', fontsize = 22)\n",
    "    axs[1].set_title('Model Predicting Time On Scene (less than 2 hours on scene)', fontsize = 22)\n",
    "    axs[2].set_title('Model Differences Based on Predicted \"Time on Scene\" ', fontsize = 22)\n",
    "\n",
    "    sns.scatterplot(data = score_frame, x = 'num_observations', y = '32.7 minutes', s = 180, alpha = .7, edgecolor = 'black', color = 'red', ax = axs[0])\n",
    "    sns.scatterplot(data = score_frame, x = 'num_observations', y= '120 minutes', s= 180, alpha = .7, edgecolor = 'black', color = 'blue', ax = axs[1])\n",
    "    sns.scatterplot(data = score_frame, x = 'num_observations', y= 'difference', s= 180, alpha = .7, edgecolor = 'black', color = 'darkgreen', ax = axs[2])\n",
    "\n",
    "    axs[2].set_ylim([0.165,.256])\n",
    "    targets = ['32.7 minutes','120 minutes','difference']\n",
    "    for i, ax in enumerate(axs):\n",
    "        ax.ticklabel_format(style = 'plain')\n",
    "        ax.xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "        ax.tick_params(size = 12)\n",
    "        ax.set_xlabel(\"Number of Observations\", fontsize = 14)\n",
    "        ax.set_ylabel('Accuracy', fontsize = 14)\n",
    "        ax.axhline(score_frame[targets[i]].max(), color = 'black', linestyle = 'dashed')\n",
    "        ax.axhline(score_frame[targets[i]].min(), color = 'black', linestyle = 'dashed')\n",
    "    axs[2].set_ylabel('Difference', fontsize = 14)\n",
    "    axs[1].set_xlabel('')\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"XGB_classifier_first_attempts.png\")\n",
    "visualize_first_attempts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a20843-7c90-4e09-8891-97c51ea777b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction_scores.rename(columns = {'accuracy': '120 minutes', '32 minute': '32.7 minutes', 'size': 'num_observations'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51323a13-e59c-48e4-8ce5-99c5194e9d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_scores['difference'] = prediction_scores['120 minutes'] - prediction_scores[\"32.7 minutes\"]\n",
    "prediction_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214568f6-9111-4d3f-a7ca-3b0a6e3bb4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_scores.to_csv('prediction_scores_xgb_baseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada40ff-3be9-4829-8c04-d31a87c071f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "other_data = pd.read_csv('xgb_classifier_attempt_1.csv')\n",
    "other_data = other_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1f34cf-9115-4723-b5a9-22d3c59899e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 13\n",
    "plt.rcParams['ytick.labelsize'] = 13\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize = (20,10))\n",
    "fig.suptitle(\"Accuracy vs. Number of Observations\", fontsize = 22)\n",
    "axs[0].set_title(\"(Not Including Call Description)\", fontsize = 15)\n",
    "axs[1].set_title(\"(Including Call Description)\", fontsize = 15)\n",
    "\n",
    "sns.scatterplot(data = other_data, x = 'size', y = 'accuracy', s = 180, alpha = .8, edgecolor = 'black', color = 'red', ax = axs[0])\n",
    "axs[0].axhline(other_data['accuracy'].max(), color = 'black', linestyle = 'dashed')\n",
    "axs[0].axhline(other_data['accuracy'].min(), color = 'black', linestyle = 'dashed')\n",
    "axs[0].axhline(other_data['accuracy'].mean(), color = 'black', linestyle = 'dashed')\n",
    "\n",
    "sns.scatterplot(data = score_frame, x = 'size', y = 'accuracy', s = 180, alpha = .8, edgecolor = 'black', color = 'red', ax = axs[1])\n",
    "axs[1].axhline(score_frame['accuracy'].max(), color = 'black', linestyle = 'dashed')\n",
    "axs[1].axhline(score_frame['accuracy'].min(), color = 'black', linestyle = 'dashed')\n",
    "axs[1].axhline(score_frame['accuracy'].mean(), color = 'black', linestyle = 'dashed')\n",
    "\n",
    "axs[0].axhline(.952, color = 'red')\n",
    "axs[1].axhline(.952, color = 'red')\n",
    "\n",
    "axs[0].set_xlabel('Number of Observations', fontsize = 15)\n",
    "axs[0].set_ylabel('Accuracy', fontsize = 15)\n",
    "axs[0].tick_params(size = 10)\n",
    "axs[0].set_xlim([1900000,2450000])\n",
    "axs[0].set_ylim([.95,.955])\n",
    "axs[0].ticklabel_format(style = 'plain')\n",
    "axs[0].xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "most_accurate = other_data[(other_data.accuracy == other_data[\"accuracy\"].max())][\"size\"].values[0]\n",
    "least_accurate = other_data[(other_data.accuracy == other_data[\"accuracy\"].min())][\"size\"].values[0]\n",
    "axs[0].annotate(f'Max Accuracy: {(other_data[\"accuracy\"].max()) * 100}% at {\"{:,}\".format(most_accurate)} observations', \n",
    "            xy= [1950000,.9536], \n",
    "            fontsize = 12)\n",
    "axs[0].annotate(f'Min Accuracy: {(other_data[\"accuracy\"].min()) * 100}% at {\"{:,}\".format(least_accurate)} observations', \n",
    "            xy= [2050000,.95156], \n",
    "            fontsize = 12)\n",
    "\n",
    "\n",
    "axs[1].set_xlabel('Number of Observations', fontsize = 15)\n",
    "axs[1].set_ylabel('Accuracy', fontsize = 15)\n",
    "axs[1].tick_params(size = 10)\n",
    "axs[1].set_xlim([1900000,2450000])\n",
    "axs[1].set_ylim([.95,.955])\n",
    "axs[1].ticklabel_format(style = 'plain')\n",
    "axs[1].xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "most_accurate = score_frame[(score_frame.accuracy == score_frame[\"accuracy\"].max())][\"size\"].values[0]\n",
    "least_accurate = score_frame[(score_frame.accuracy == score_frame[\"accuracy\"].min())][\"size\"].values[0]\n",
    "axs[1].annotate(f'Max Accuracy: {(score_frame[\"accuracy\"].max()) * 100}% at {\"{:,}\".format(most_accurate)} observations', \n",
    "            xy= [1950000,.9532], \n",
    "            fontsize = 12)\n",
    "axs[1].annotate(f'Min Accuracy: {(score_frame[\"accuracy\"].min()) * 100}% at {\"{:,}\".format(least_accurate)} observations', \n",
    "            xy= [2050000,.951], \n",
    "            fontsize = 12)\n",
    "\n",
    "sns.set\n",
    "\n",
    "sns.despine()\n",
    "#plt.savefig(\"XGB_classifier_vs-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4363dbc6-0f4e-4350-8f4f-6647a5fb9e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e6f018-3674-4a92-b420-cd254fcd4952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19fc63-9c9a-44a8-896c-51043c387f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = tree_model.get_booster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7de4e3-adb5-40a7-9dc1-61bc1dfe5398",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_params = {'shape': 'box',\n",
    "              'style': 'filled, rounded',\n",
    "              'fillcolor': '#1AA7EC'}\n",
    "leaf_params = {'shape': 'box',\n",
    "              'style': 'filled',\n",
    "              'fillcolor': '#FFFF00'}\n",
    "\n",
    "\n",
    "tree_graph = xgb.to_graphviz(tree_model,\n",
    "                num_trees=0,\n",
    "                size=\"10,10\",\n",
    "                condition_node_params=node_params,\n",
    "                leaf_node_params=leaf_params, \n",
    "                bgcolor = 'transparent',\n",
    "                yes_color = 'green',\n",
    "                no_color = 'red'\n",
    "               )\n",
    "\n",
    "tree_graph.render('graphs/single_tree_sample', format='png', view = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4151ce35-b522-45ec-804b-038f096f3e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
